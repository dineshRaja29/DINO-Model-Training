{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshRaja29/DINO-Model-Training/blob/main/DINO_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> DATA PREPARATION"
      ],
      "metadata": {
        "id": "6fhKB3mCG-rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Considering the CIFAR - 10 dataset\n",
        "- Converting this dataset into binary dataset [which have label as 0 or 1]\n",
        "- Converting this dataset into unbalalanced dataset by converting labels '0' as '0' and rest eveything label as '1'"
      ],
      "metadata": {
        "id": "niPuzQCrHHEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:16:14.780958Z",
          "iopub.execute_input": "2025-06-19T07:16:14.781133Z",
          "iopub.status.idle": "2025-06-19T07:16:44.040389Z",
          "shell.execute_reply.started": "2025-06-19T07:16:14.781118Z",
          "shell.execute_reply": "2025-06-19T07:16:44.039818Z"
        },
        "id": "Tznj5fpzGq8y",
        "outputId": "04de2a20-fbfd-41cb-ff99-2e932cc64416"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 170M/170M [00:15<00:00, 11.2MB/s] \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def label_adjustment(dataset):\n",
        "    results = []\n",
        "    for img, label in dataset:\n",
        "        if label == 0:\n",
        "            results.append([img, label])\n",
        "        if label == 1 or label == 2:\n",
        "             results.append([img, 1])\n",
        "    return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:16:44.042151Z",
          "iopub.execute_input": "2025-06-19T07:16:44.042539Z",
          "iopub.status.idle": "2025-06-19T07:16:44.047019Z",
          "shell.execute_reply.started": "2025-06-19T07:16:44.042521Z",
          "shell.execute_reply": "2025-06-19T07:16:44.046446Z"
        },
        "id": "wIsiQrJhGq80"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = label_adjustment(train_set)\n",
        "test_data  = label_adjustment(test_set)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:16:44.04764Z",
          "iopub.execute_input": "2025-06-19T07:16:44.047875Z",
          "iopub.status.idle": "2025-06-19T07:16:50.392753Z",
          "shell.execute_reply.started": "2025-06-19T07:16:44.047861Z",
          "shell.execute_reply": "2025-06-19T07:16:50.392155Z"
        },
        "id": "WzM3RNEAGq81"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_root = '/content/drive/MyDrive/cifar10_binary'\n",
        "os.makedirs(save_root, exist_ok = True)\n",
        "to_pil = ToPILImage()\n",
        "\n",
        "def save_images_and_make_csv(data, split_name):\n",
        "    dir = os.path.join(save_root, split_name)\n",
        "    os.makedirs(dir, exist_ok = True)\n",
        "    rows = []\n",
        "    for idx, (img_tensor, label) in enumerate(data):\n",
        "        img_path = os.path.join(dir, f'{idx}.png')\n",
        "        to_pil(img_tensor).save(img_path)\n",
        "        rows.append([img_path, label])\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=[\"MD5HASH\", \"LABEL\"])\n",
        "    df.to_csv(os.path.join(save_root, f\"{split_name}.csv\"), index = False)\n",
        "    print(f\"{split_name}.csv saved with {len(rows)} entries.\")\n",
        "\n",
        "# Save both splits\n",
        "save_images_and_make_csv(train_data, \"train\")\n",
        "save_images_and_make_csv(test_data, \"test\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:16:50.393471Z",
          "iopub.execute_input": "2025-06-19T07:16:50.393707Z",
          "iopub.status.idle": "2025-06-19T07:16:58.655311Z",
          "shell.execute_reply.started": "2025-06-19T07:16:50.393687Z",
          "shell.execute_reply": "2025-06-19T07:16:58.654473Z"
        },
        "id": "RuTh0O8VGq83",
        "outputId": "15ec9f8e-3f80-4c1a-9be4-a1e1547b23ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "train.csv saved with 15000 entries.\ntest.csv saved with 3000 entries.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/cifar10_binary"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:16:58.656128Z",
          "iopub.execute_input": "2025-06-19T07:16:58.656375Z",
          "iopub.status.idle": "2025-06-19T07:16:58.801611Z",
          "shell.execute_reply.started": "2025-06-19T07:16:58.656334Z",
          "shell.execute_reply": "2025-06-19T07:16:58.800785Z"
        },
        "id": "G-N7o_ThGq84",
        "outputId": "0364787b-c378-49b3-91fa-ffd130839e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "test  test.csv\ttrain  train.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> IMPORTING LIBRARIES AND SETTING CONGIURATION PARAMETERS"
      ],
      "metadata": {
        "id": "RtUZHnl3H3KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoFeatureExtractor, Dinov2Model\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# note: PIL stands for pillow; to install type \"pip3 install pillow\"\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from torchvision.transforms import Compose, Resize, RandomResizedCrop, RandomHorizontalFlip, ColorJitter, ToTensor, Normalize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, gc"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:16:58.802782Z",
          "iopub.execute_input": "2025-06-19T07:16:58.803071Z",
          "iopub.status.idle": "2025-06-19T07:17:16.551444Z",
          "shell.execute_reply.started": "2025-06-19T07:16:58.80304Z",
          "shell.execute_reply": "2025-06-19T07:17:16.550847Z"
        },
        "id": "qfmsiB9SGq85",
        "outputId": "35961e85-4d95-4e06-dad9-13308b295db9"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-06-19 07:17:03.011678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750317423.209937      70 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750317423.267046      70 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for CUDA and MPS availability, set the device accordingly\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    # setting environment variables, need to run training in MacOS\n",
        "    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
        "    os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "    print(\"Using MPS as the device.\")\n",
        "else:\n",
        "    if torch.cuda.is_available():\n",
        "\t# the syntax 'cuda:3' used to point a specific GPU from the cluster of GPUs\n",
        "\t# 'cuda' points to first GPU from the cluster of GPUs\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"Using CUDA as the device.\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU as the device.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:16.552253Z",
          "iopub.execute_input": "2025-06-19T07:17:16.552977Z",
          "iopub.status.idle": "2025-06-19T07:17:16.558152Z",
          "shell.execute_reply.started": "2025-06-19T07:17:16.552952Z",
          "shell.execute_reply": "2025-06-19T07:17:16.557362Z"
        },
        "id": "XT8NF602Gq86",
        "outputId": "9d27c85c-bcf7-4844-c385-a521c16684e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using CUDA as the device.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DATA                         = '/content/drive/MyDrive/cifar10_binary/train.csv'\n",
        "TESTING_DATA                          = '/content/drive/MyDrive/cifar10_binary/test.csv'\n",
        "BATCH_SIZE                            = 32#256\n",
        "WORKERS                               = 4\n",
        "PIN_MEMORY                            = True\n",
        "MIXING                                = True\n",
        "MODEL_NAME                            = \"facebook/dinov2-base\"\n",
        "RESULTS                               = 'results'\n",
        "EPOCHS                                = 4\n",
        "BEST_MODEL                            = None\n",
        "PRETRAINING                           = False\n",
        "LEARNING_RATE                         = 5e-5\n",
        "L2_PENALTY                            = 1e-5\n",
        "GAMMA                                 = 0.1\n",
        "STEPSIZE                              = 3\n",
        "SAVE_CHECKPOINTS                      = True\n",
        "MIN_LOSS                              = float('inf')\n",
        "MODEL_SAVED                           = f'{RESULTS}/bestmodel.pth'\n",
        "THRESHOLD                             = 0.5\n",
        "OUTPUT_DIM                            = 1\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:16.559125Z",
          "iopub.execute_input": "2025-06-19T07:17:16.559435Z",
          "iopub.status.idle": "2025-06-19T07:17:16.584782Z",
          "shell.execute_reply.started": "2025-06-19T07:17:16.559408Z",
          "shell.execute_reply": "2025-06-19T07:17:16.584179Z"
        },
        "id": "-63FKRMjGq88"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> PERFORMANCE METRIC [PRECISION & RECALL]"
      ],
      "metadata": {
        "id": "KQXKHO1PII6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_classification_accuracy(loader, model):\n",
        "    model.eval()  # Set the model in evaluation mode\n",
        "    LABELS = []\n",
        "    PREDICTIONS = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            # Move to device and cast to float32\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "            probabilities = model(images).squeeze()\n",
        "            # Predictions based on the threshold\n",
        "            prediction = torch.where(probabilities > THRESHOLD, 1.0, 0.0)\n",
        "            LABELS.extend(labels.tolist())\n",
        "            PREDICTIONS.extend(prediction.tolist())\n",
        "    return classification_report(LABELS, PREDICTIONS)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:16.585554Z",
          "iopub.execute_input": "2025-06-19T07:17:16.585822Z",
          "iopub.status.idle": "2025-06-19T07:17:16.598894Z",
          "shell.execute_reply.started": "2025-06-19T07:17:16.5858Z",
          "shell.execute_reply": "2025-06-19T07:17:16.598286Z"
        },
        "id": "a1UvIXqHGq8-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> DINO MODEL [WITH ADDITIONAL CLASSIFICATION HEAD]"
      ],
      "metadata": {
        "id": "EPcFvaNxIQG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        # taking processor for necessary substitions, if needed in later stages\n",
        "        self.processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
        "        self.model = Dinov2Model.from_pretrained(MODEL_NAME)\n",
        "        self.pretrained_model_last_dim = self.model.layernorm.normalized_shape[0]\n",
        "\n",
        "        # Additional classification head used for downstreaming tasks\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.Linear(self.pretrained_model_last_dim, OUTPUT_DIM, bias = True),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        self.initialize_weights() # weights initialization from kaiming instead of random\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        torch.manual_seed(444)\n",
        "        for layer in self.cls_head:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(layer.weight, nonlinearity = 'relu')\n",
        "                nn.init.zeros_(layer.bias)\n",
        "                print(f\"kaiming_uniform_ Initialization: {layer.__class__.__name__}\")\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x).last_hidden_state[:, 0]\n",
        "        x = self.cls_head(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:16.59972Z",
          "iopub.execute_input": "2025-06-19T07:17:16.600422Z",
          "iopub.status.idle": "2025-06-19T07:17:16.617331Z",
          "shell.execute_reply.started": "2025-06-19T07:17:16.6004Z",
          "shell.execute_reply": "2025-06-19T07:17:16.616567Z"
        },
        "id": "9CVAsVXZGq8_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network()\n",
        "\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:16.620179Z",
          "iopub.execute_input": "2025-06-19T07:17:16.620856Z",
          "iopub.status.idle": "2025-06-19T07:17:22.135354Z",
          "shell.execute_reply.started": "2025-06-19T07:17:16.620834Z",
          "shell.execute_reply": "2025-06-19T07:17:22.134718Z"
        },
        "id": "NG9HbUnfGq9A",
        "outputId": "12b97982-5d65-47e1-c8f5-cd0409d5d851",
        "colab": {
          "referenced_widgets": [
            "da17bba894e64119a6e559d85b1ca745",
            "911f4f28a9284b1fb99f7cf41ac6b1d4",
            "1c917ca0f04d4a31a28c355302d45b70"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da17bba894e64119a6e559d85b1ca745"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/548 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "911f4f28a9284b1fb99f7cf41ac6b1d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c917ca0f04d4a31a28c355302d45b70"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "kaiming_uniform_ Initialization: Linear\n",
          "output_type": "stream"
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Network(\n  (model): Dinov2Model(\n    (embeddings): Dinov2Embeddings(\n      (patch_embeddings): Dinov2PatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): Dinov2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x Dinov2Layer(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attention): Dinov2Attention(\n            (attention): Dinov2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (output): Dinov2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (layer_scale1): Dinov2LayerScale()\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Dinov2MLP(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (activation): GELUActivation()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_scale2): Dinov2LayerScale()\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  )\n  (cls_head): Sequential(\n    (0): Linear(in_features=768, out_features=1, bias=True)\n    (1): Sigmoid()\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> DATA LOADER WITH UPSAMPLING"
      ],
      "metadata": {
        "id": "dHV5gu0qIbTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MD5HASHDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.images = self.dataframe['MD5HASH'].values\n",
        "        self.labels = self.dataframe['LABEL'].values\n",
        "        self.processor = model.processor\n",
        "        self.mean = self.processor.image_mean\n",
        "        self.std = self.processor.image_std\n",
        "        self.interpolation = self.processor.resample\n",
        "\n",
        "        self.train_transform = Compose([\n",
        "            Resize(size = (32, 32)),\n",
        "            #Resize(size = (85, 550)),\n",
        "            #RandomResizedCrop(size = (224, 224),\n",
        "            #                  scale = (0.08, 1.0),\n",
        "            #                  ratio = (0.75, 1.3333),\n",
        "            #                  interpolation = self.interpolation),\n",
        "            #RandomHorizontalFlip(p = 0.5),\n",
        "            #ColorJitter(brightness = (0.6, 1.4),\n",
        "            #            contrast = (0.6, 1.4),\n",
        "            #            saturation = (0.6, 1.4)),\n",
        "            ToTensor(),\n",
        "            Normalize(mean = self.mean, std = self.std),\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load the image from the file path\n",
        "        image_path = self.images[idx]\n",
        "        image = self.train_transform(Image.open(image_path).convert('RGB'))\n",
        "        # Get the label\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:22.136052Z",
          "iopub.execute_input": "2025-06-19T07:17:22.136313Z",
          "iopub.status.idle": "2025-06-19T07:17:22.142402Z",
          "shell.execute_reply.started": "2025-06-19T07:17:22.136295Z",
          "shell.execute_reply": "2025-06-19T07:17:22.141702Z"
        },
        "id": "mxggeRnFGq9B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_loader(data_csv = TRAINING_DATA, upsampling = False):\n",
        "    # Load data\n",
        "    training_data = pd.read_csv(data_csv)\n",
        "    print('::: TRAINING DATA DETAILS :::')\n",
        "    print('- Number of Samples:', training_data.shape[0])\n",
        "    print('- LABEL DISTRIBUTION: \\n',training_data['LABEL'].value_counts())\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    md5hash_dataset = MD5HASHDataset(training_data)\n",
        "    if upsampling:\n",
        "        # References:\n",
        "        # https://pytorch.org/docs/stable/data.html\n",
        "        # https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452\n",
        "        from torch.utils.data import WeightedRandomSampler\n",
        "        classes_count = dict(training_data['LABEL'].value_counts())\n",
        "        sample_weights = [ 1 / classes_count[i] for i in training_data.LABEL.values]\n",
        "        sampler = WeightedRandomSampler(weights = sample_weights,\n",
        "                                        num_samples = len(training_data),\n",
        "                                        replacement = True)\n",
        "        data_loader = DataLoader(md5hash_dataset,\n",
        "                                 batch_size = BATCH_SIZE,\n",
        "                                 num_workers = WORKERS,\n",
        "                                 pin_memory = PIN_MEMORY,\n",
        "                                 shuffle = False,\n",
        "                                 sampler = sampler)\n",
        "    else:\n",
        "        data_loader = DataLoader(md5hash_dataset,\n",
        "                                 batch_size = BATCH_SIZE,\n",
        "                                 num_workers = WORKERS,\n",
        "                                 pin_memory = PIN_MEMORY,\n",
        "                                 shuffle = MIXING)\n",
        "\n",
        "    # Clean memory, :)\n",
        "    del training_data\n",
        "\n",
        "    return data_loader\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:22.143193Z",
          "iopub.execute_input": "2025-06-19T07:17:22.143403Z",
          "iopub.status.idle": "2025-06-19T07:17:22.16369Z",
          "shell.execute_reply.started": "2025-06-19T07:17:22.14338Z",
          "shell.execute_reply": "2025-06-19T07:17:22.16307Z"
        },
        "id": "R0b56KDaGq9D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = create_training_loader(upsampling = True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:22.164446Z",
          "iopub.execute_input": "2025-06-19T07:17:22.164717Z",
          "iopub.status.idle": "2025-06-19T07:17:22.218747Z",
          "shell.execute_reply.started": "2025-06-19T07:17:22.164695Z",
          "shell.execute_reply": "2025-06-19T07:17:22.218115Z"
        },
        "id": "r28d6HWkGq9E",
        "outputId": "46124fa5-d0e4-4a9a-bfcd-efb7dc8b69e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "::: TRAINING DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n1    10000\n0     5000\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> OPTIMIZER, SCHEDULER AND LOSS FUNCTION"
      ],
      "metadata": {
        "id": "qAzXSZDWIkvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## MODEL TRAINING\n",
        "\n",
        "# Define the optimizer\n",
        "# Idea borrowed from Research paper titled as \"Improving Generalization Performance by Switching from Adam to SGD\"\n",
        "if PRETRAINING:\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum = 0.9, weight_decay = L2_PENALTY)\n",
        "else:\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = L2_PENALTY)\n",
        "\n",
        "# Define a learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size = STEPSIZE, gamma = GAMMA)  # Adjust step_size and gamma as needed\n",
        "# Define the loss function: BCE\n",
        "criterion = nn.BCELoss()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:22.219511Z",
          "iopub.execute_input": "2025-06-19T07:17:22.219789Z",
          "iopub.status.idle": "2025-06-19T07:17:22.225101Z",
          "shell.execute_reply.started": "2025-06-19T07:17:22.219764Z",
          "shell.execute_reply": "2025-06-19T07:17:22.224428Z"
        },
        "id": "t8wxNJW0Gq9E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# directory creation\n",
        "os.makedirs(RESULTS, exist_ok = True)\n",
        "if SAVE_CHECKPOINTS:\n",
        "    CHECKPOINTDIR = f'{RESULTS}/checkpoints'\n",
        "    os.makedirs(CHECKPOINTDIR, exist_ok = True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:22.225781Z",
          "iopub.execute_input": "2025-06-19T07:17:22.226043Z",
          "iopub.status.idle": "2025-06-19T07:17:22.244451Z",
          "shell.execute_reply.started": "2025-06-19T07:17:22.226021Z",
          "shell.execute_reply": "2025-06-19T07:17:22.243944Z"
        },
        "id": "KtdaudZfGq9F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> MODEL FINE-TUNING TRAINING"
      ],
      "metadata": {
        "id": "-7h-_oLsIt6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING LOOP\n",
        "for epoch in range(EPOCHS):\n",
        "    print('-'*70)\n",
        "    # Define the total number of batches in the loader\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # setting model stage to training\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(data_loader):\n",
        "        # shifting to MPS\n",
        "        # Shift to MPS and then cast to float32\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()  # Moved this line here to avoid accumulating gradients\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "            # Forward pass\n",
        "            outputs = model(images).squeeze()  # Squeeze to remove extra dimensions\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Explicitly free up GPU memory\n",
        "        if torch.backends.mps.is_available():\n",
        "            torch.backends.mps.is_macos13_or_newer.cache_clear()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        # Run garbage collector to free up CPU memory\n",
        "        gc.collect()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / (batch_idx + 1)}\")\n",
        "    print('TRAINING DATA')\n",
        "    print(f'- Performance: \\n{calculate_classification_accuracy(data_loader, model)}')\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "    if SAVE_CHECKPOINTS:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "        checkpointmodel = '{}/epoch_{}_{}.pth'.format(CHECKPOINTDIR, epoch + 1, timestamp)\n",
        "        print('Saving checkpoint: ', checkpointmodel)\n",
        "        torch.save(model.state_dict(), checkpointmodel)\n",
        "\n",
        "    # Check if this epoch had the minimum loss\n",
        "    if total_loss < MIN_LOSS:\n",
        "        MIN_LOSS = total_loss\n",
        "        best_model = model.state_dict()\n",
        "        # Save the best model\n",
        "        if best_model is not None:\n",
        "            print('Saving Best Model: ', MODEL_SAVED)\n",
        "            torch.save(best_model, MODEL_SAVED)\n",
        "\n",
        "################################\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:17:22.245066Z",
          "iopub.execute_input": "2025-06-19T07:17:22.245294Z",
          "iopub.status.idle": "2025-06-19T07:30:56.359598Z",
          "shell.execute_reply.started": "2025-06-19T07:17:22.245279Z",
          "shell.execute_reply": "2025-06-19T07:30:56.358545Z"
        },
        "id": "2REq6xfYGq9F",
        "outputId": "b2511311-3080-4cf6-a7a2-11faa0f42b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "----------------------------------------------------------------------\nEpoch 1/4, Loss: 0.4652398204101301\nTRAINING DATA\n- Performance: \n              precision    recall  f1-score   support\n\n         0.0       0.88      0.90      0.89      7477\n         1.0       0.90      0.87      0.89      7523\n\n    accuracy                           0.89     15000\n   macro avg       0.89      0.89      0.89     15000\nweighted avg       0.89      0.89      0.89     15000\n\nSaving checkpoint:  results/checkpoints/epoch_1_20250619072045.pth\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 2/4, Loss: 0.18003429818366254\nTRAINING DATA\n- Performance: \n              precision    recall  f1-score   support\n\n         0.0       0.92      0.98      0.95      7466\n         1.0       0.98      0.91      0.94      7534\n\n    accuracy                           0.94     15000\n   macro avg       0.95      0.94      0.94     15000\nweighted avg       0.95      0.94      0.94     15000\n\nSaving checkpoint:  results/checkpoints/epoch_2_20250619072407.pth\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 3/4, Loss: 0.12192414922000312\nTRAINING DATA\n- Performance: \n              precision    recall  f1-score   support\n\n         0.0       0.97      0.95      0.96      7550\n         1.0       0.95      0.97      0.96      7450\n\n    accuracy                           0.96     15000\n   macro avg       0.96      0.96      0.96     15000\nweighted avg       0.96      0.96      0.96     15000\n\nSaving checkpoint:  results/checkpoints/epoch_3_20250619072732.pth\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 4/4, Loss: 0.05339157602428071\nTRAINING DATA\n- Performance: \n              precision    recall  f1-score   support\n\n         0.0       0.99      1.00      0.99      7483\n         1.0       1.00      0.99      0.99      7517\n\n    accuracy                           0.99     15000\n   macro avg       0.99      0.99      0.99     15000\nweighted avg       0.99      0.99      0.99     15000\n\nSaving checkpoint:  results/checkpoints/epoch_4_20250619073055.pth\nSaving Best Model:  results/bestmodel.pth\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(MODEL_SAVED, weights_only = True))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:31:34.004988Z",
          "iopub.execute_input": "2025-06-19T07:31:34.005301Z",
          "iopub.status.idle": "2025-06-19T07:31:34.288903Z",
          "shell.execute_reply.started": "2025-06-19T07:31:34.005271Z",
          "shell.execute_reply": "2025-06-19T07:31:34.288226Z"
        },
        "id": "eQBDBFpZGq9G",
        "outputId": "dac82b1a-1ad8-4ea2-9fe3-624ce0140eda"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> RESULTS ON ORIGINAL TRAINING AND TEST DATA"
      ],
      "metadata": {
        "id": "Aq4oKDL4I2rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = create_training_loader() # without upsampling, used to report exact performance on the training data\n",
        "\n",
        "# getting Best model performance on training, validation and testing data, if it is available\n",
        "print('TRAINING DATA')\n",
        "print(f'- Performance: \\n{calculate_classification_accuracy(data_loader, model)}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:31:45.207462Z",
          "iopub.execute_input": "2025-06-19T07:31:45.208133Z",
          "iopub.status.idle": "2025-06-19T07:31:52.2631Z",
          "shell.execute_reply.started": "2025-06-19T07:31:45.208098Z",
          "shell.execute_reply": "2025-06-19T07:31:52.262147Z"
        },
        "id": "3gY6QDo8Gq9H",
        "outputId": "556bcd77-3336-4fb2-a8a2-ef056545a896"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "::: TRAINING DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n1    10000\n0     5000\nName: count, dtype: int64\nTRAINING DATA\n- Performance: \n              precision    recall  f1-score   support\n\n         0.0       0.98      1.00      0.99      5000\n         1.0       1.00      0.99      0.99     10000\n\n    accuracy                           0.99     15000\n   macro avg       0.99      0.99      0.99     15000\nweighted avg       0.99      0.99      0.99     15000\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "testset_loader = create_training_loader(data_csv = TESTING_DATA, upsampling = False)\n",
        "\n",
        "print('TESTING DATA')\n",
        "print(f'- Performance: \\n{calculate_classification_accuracy(testset_loader, model)}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T07:31:57.257798Z",
          "iopub.execute_input": "2025-06-19T07:31:57.258105Z",
          "iopub.status.idle": "2025-06-19T07:31:58.892171Z",
          "shell.execute_reply.started": "2025-06-19T07:31:57.25808Z",
          "shell.execute_reply": "2025-06-19T07:31:58.891365Z"
        },
        "id": "sKOePnMoGq9I",
        "outputId": "c9d9011c-228f-4281-ff99-69533322cfbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "::: TRAINING DATA DETAILS :::\n- Number of Samples: 3000\n- LABEL DISTRIBUTION: \n LABEL\n1    2000\n0    1000\nName: count, dtype: int64\nTESTING DATA\n- Performance: \n              precision    recall  f1-score   support\n\n         0.0       0.90      0.88      0.89      1000\n         1.0       0.94      0.95      0.95      2000\n\n    accuracy                           0.93      3000\n   macro avg       0.92      0.92      0.92      3000\nweighted avg       0.93      0.93      0.93      3000\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}